#Desktop

# Images of Image Machines. Theory and Practice of Interpretable Machine Learning for the Digital Humanities

While text is still the most important research topic in the digital humanities, over the past ten years images have started to gradually appear on the radar of computational humanists. Recent developments in digital art history in particular have shown that the importance of images for DH research goes beyond ensuring their accessibility through databases and interfaces. In fact, images are where digital humanities and artificial intelligence meet. Most importantly, the automated classification of images on the one hand, and the automated production of images on the other raise a fundamental question at the interface of computer science and the humanities: how is reality represented in machine learning systems? The field of interpretable machine learning is concerned with opening the black box and answering this question.

This two-week workshop will serve as an introduction to the theory and practice of interpretable machine learning. The first week will introduce participants to the field by means of reading, discussing, and replicating foundational results in interpretable machine learning, with a particular focus on the fairness, accountability, and transparency (FAT) of machine learning systems. The second week will be dedicated to hands-on experimentation with image datasets in [PyTorch](https://pytorch.org/), a popular machine learning framework. While the first week has no prerequisites, the second week requires basic programming skills, preferably in Python. 

## Readings

Readings/materials that are not directly linked here are provided via a shared Google Drive folder distributed to the participants via the workshop Moodle.

- Agre, Philip E.. "[The Soul Gained and Lost. Artificial Intelligence as a Philosophical Project](https://web.stanford.edu/group/SHR/4-2/text/agre.html)." SEHR 4, no. 2, 1995.
- Babbage, Charles. "On the Economy of Machinery and Manufactures". In: *Babbage's Calculating Engines. Being a Collection of Papers Relating to Them; Their History, and Construction*. Cambridge: Cambridge University Press, 2010.
- Burrell, Jenna. "How the Machine ‘Thinks’: Understanding Opacity in Machine Learning Algorithms". Big Data & Society 3, no. 1, 2016.
- Clark, Timothy J.. "Art History in an Age of Image Machines." EurAmerica 38, no. 1 (2008).
- Crawford, Kate, et. al.. [Anatomy of an AI System]( https://anatomyof.ai), 2018.
- Crawford, Kate. "[The Trouble with Bias](https://www.youtube.com/watch?v=fMym_BKWQzk&t=698s)." Keynote at NIPS2017, Long Beach, California, USA, 2017.
- Descartes, René. Discourse on Method, Part V. In: Philosophical Essays and Correspondence. Indianapolis, IN: Hackett Publishing, 2000.
- Drucker, Johanna. "Is There a Digital Art History?" Visual Resources 29, no. 1-2, 2003.
- Jonas, Eric, and Kording, Konrad Paul. "Could a Neuroscientist Understand a Microprocessor?" PLoSComputBiol 13, no. 1, 2017.
- Kittler, Friedrich. "Protected Mode". In: Literature, Media, Information Systems. London: Routledge, 2012.
- Kurenkov, Andrey. [A 'Brief' History of Neural Nets and Deep Learning](http://www.andreykurenkov.com/writing/ai/a-brief-history-of-neural-nets-and-deep-learning/), 2015.
- Mittelstadt, Brent  et. al. "Explaining Explanations in AI". 2019 ACM Conference on Fairness, Accountability, and Transparency (FAT*).
- Molnar, Christoph. [The Interpretable Machine Learning Book](https://christophm.github.io/interpretable-ml-book/) (2019).
- Moretti, Franco and Impett, Leonardo. "Totentanz. Operationalizing Aby Warburg's Pathosformeln". New Left Review 107, September/October 2017.
- Olah, Chris et. al.. [The Building Blocks of Interpretability](https://distill.pub/2018/building-blocks/), 2018.
- Selbst, Andrew D. and Barocas, Solon. "The Intuitive Appeal of Explainable Machines". Fordham Law Review 87, 2018.
- Speer, Robyn. [How to Make a Racist AI Without Really Trying](https://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/), 2017.
- Turing, Alan M.. "Computing Machinery and Intelligence". Mind 59, no. 236, 1950.

## Preliminary Schedule

## First Week

- TUE 1a: Participant introductions, collection of interests, introduction to the topic: the workshop in 60 minutes
- TUE 2a: Readings and discussion: artificial intelligence and machine learning
- WED 3a: Readings and discussion: interpretable machine learning
- WED 4a: Readings and discussion: fairness, accountability, and transparency
- THU 5a: Introduction to image datasets
- FRI 6a: Refresher: Python for DH in 90 minutes
- FRI 7a: Introduction to tools, frameworks, notebooks
- SAT 8a: Reading and writing images with Python I
- SAT 9a: Reading and writing images with Python II

## Second Week

- MON 1b: Introduction to neural networks for image classification I
- MON 2b: Introduction to neural networks for image classification II
- TUE 3b: Collecting and cleaning image datasets with Python
- TUE 4b: Exploring and understanding image datasets with machine learning
- WED 5b: TBD
- THU 6b: Feature visualization: theory and practice
- THU 7b: Generative adversarial networks: theory and practice
- FRI 8b: Project work
- FRI 9b: Conclusion and preparation for presentation

## Tutorials

Official Python tutorial:
Python beginner's website

Deep learning book:
- [Stanford CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/)
- [Deep Learning book (Goodfellow)](http://www.deeplearningbook.org/)
- [Google Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/)
- [Amazon Machine Learning Course](https://aws.amazon.com/training/learning-paths/machine-learning/)





